{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cf2f675-2c27-42a8-b05b-c7b50840ee0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n!pip install mss\\n!pip install matplotlib\\n!pip install tensorboardX python-dotenv\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "!pip install mss\n",
    "!pip install matplotlib\n",
    "!pip install tensorboardX python-dotenv\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03d28b0",
   "metadata": {},
   "source": [
    "## preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6abbb04-bd69-4f55-bb60-83ed10164b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug\n",
    "import time\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93856579",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "EXECUTABLE_NAME = os.getenv('EXECUTABLE_NAME')\n",
    "GAME_WINDOW_NAME = os.getenv('GAME_WINDOW_NAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11af99ca-18a5-405f-8a6e-dfe1d0a674fc",
   "metadata": {},
   "source": [
    "### camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f99a2bed-5bca-4d68-9fef-414956377d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buffer_started\n"
     ]
    }
   ],
   "source": [
    "from src.gamenv import GameEnv\n",
    "\n",
    "# offset\n",
    "\n",
    "keep_frames = 60  # Number of frames to stack\n",
    "skip_frames = 4\n",
    "n_stack = 4 #keep_frames // skip_frames\n",
    "\n",
    "game_env = GameEnv(n_stack, \"snes9x.exe\", \"mario - Snes9x 1.62.3\", (200, 150, 550, 500))\n",
    "camera = game_env.camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edd11d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 80)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "frame = camera.get_frame()\n",
    "plt.imshow(frame)\n",
    "frame.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8d0541",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a1c03cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium\n",
    "\n",
    "# Register the custom environment with Gym\n",
    "from gymnasium.envs.registration import register\n",
    "\n",
    "register(\n",
    "    id='CustomGameEnv-v0',\n",
    "    entry_point='src.gamenv.gameenv:GameEnv',\n",
    "    max_episode_steps=None,  # Adjust as needed\n",
    ")\n",
    "\n",
    "# Create the environment\n",
    "# env = gymnasium.make('CustomGameEnv-v0')\n",
    "\n",
    "# obs = env.reset()\n",
    "# for _ in range(500):  # Adjust as needed\n",
    "#     action = env.action_space.sample()  # Replace with your RL agent's action\n",
    "#     obs, reward, done, truncated, info = env.step(action)\n",
    "#     env.render()\n",
    "#     if done or truncated:\n",
    "#         obs = env.reset()\n",
    "# env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2b0bc71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\my tools\\environments\\pytorch_2_1_0_cuda_11_8\\Lib\\site-packages\\gymnasium\\envs\\registration.py:481: UserWarning: \u001b[33mWARN: The environment creator metadata doesn't include `render_modes`, contains: ['render.modes']\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buffer_started\n"
     ]
    }
   ],
   "source": [
    "import gymnasium\n",
    "import numpy as np\n",
    "from gymnasium import spaces\n",
    "\n",
    "env = gymnasium.make('CustomGameEnv-v0')\n",
    "\n",
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])\n",
    "def norm_obs(obs):\n",
    "    obs = obs.astype(np.float32) / 255.0  # Scale to [0, 1]\n",
    "    # Normalize the image\n",
    "    return (obs - mean) / std\n",
    "\n",
    "class FrameStackingWrapper(gymnasium.Wrapper):\n",
    "    def __init__(self, env, keep_frames=4):\n",
    "        super(FrameStackingWrapper, self).__init__(env)\n",
    "        self.keep_frames = keep_frames\n",
    "        self.frames = np.zeros((keep_frames, *env.observation_space.shape), dtype=np.float32)\n",
    "        \n",
    "        # self.observation_space = spaces.Box(low=-2.1179, high=2.6400, shape=(n_stack, 180, 180, 3), dtype=np.float32)\n",
    "        self.observation_space = spaces.Box(low=0, high=255, shape=(1, 80, 80), dtype=np.uint8)\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        obs, info = self.env.reset(**kwargs)\n",
    "        # self.frames = np.zeros((self.keep_frames, *self.env.observation_space.shape), dtype=np.float32)\n",
    "        # for i in range(self.keep_frames):\n",
    "        #     self.frames[i] = obs.astype(np.float32) / 255.0 # norm_obs(obs)\n",
    "        # stacked_obs = np.array([self.frames[-1-i] for i in range(keep_frames-1, -1, -1) if i % skip_frames==0])\n",
    "        # return stacked_obs, info\n",
    "        return obs[-1], info\n",
    "\n",
    "    def step(self, action):\n",
    "        obs, reward, done, truncated, info = self.env.step(action)\n",
    "        # self.frames[:-1] = self.frames[1:]  # Shift frames\n",
    "        # self.frames[-1] = obs.astype(np.float32) / 255.0 # norm_obs(obs) # add frame\n",
    "        # stacked_obs = np.array([self.frames[-1-i] for i in range(keep_frames-1, -1, -1) if i % skip_frames==0])\n",
    "        # return stacked_obs, reward, done, truncated, info\n",
    "        return obs[-1], reward, done, truncated, info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57b105ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-57, -53, -49, -45, -41, -37, -33, -29, -25, -21, -17, -13, -9, -5, -1]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list([-1-i for i in range(keep_frames-1, -1, -1) if i % skip_frames==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64c4ecb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env.vec_frame_stack import VecFrameStack\n",
    "\n",
    "env = FrameStackingWrapper(env, keep_frames=keep_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a22065f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 80, 80)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs, _ = env.reset()\n",
    "obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "257356cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.sample().shape[-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b48af930",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.v2 as transforms\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "\n",
    "from stable_baselines3.common.preprocessing import is_image_space\n",
    "\n",
    "class CustomCNN(BaseFeaturesExtractor):\n",
    "    \"\"\"\n",
    "    :param observation_space:\n",
    "    :param features_dim: Number of features extracted.\n",
    "        This corresponds to the number of unit for the last layer.\n",
    "    :param normalized_image: Whether to assume that the image is already normalized\n",
    "        or not (this disables dtype and bounds checks): when True, it only checks that\n",
    "        the space is a Box and has 3 dimensions.\n",
    "        Otherwise, it checks that it has expected dtype (uint8) and bounds (values in [0, 255]).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        observation_space: gymnasium.Space,\n",
    "        features_dim: int = 512,\n",
    "        normalized_image: bool = False,\n",
    "    ) -> None:\n",
    "        assert isinstance(observation_space, spaces.Box), (\n",
    "            \"NatureCNN must be used with a gym.spaces.Box \",\n",
    "            f\"observation space, not {observation_space}\",\n",
    "        )\n",
    "        super().__init__(observation_space, features_dim)\n",
    "        # We assume CxHxW images (channels first)\n",
    "        # Re-ordering will be done by pre-preprocessing or wrapper\n",
    "        assert is_image_space(observation_space, check_channels=False, normalized_image=normalized_image), (\n",
    "            \"You should use NatureCNN \"\n",
    "            f\"only with images not with {observation_space}\\n\"\n",
    "            \"(you are probably using `CnnPolicy` instead of `MlpPolicy` or `MultiInputPolicy`)\\n\"\n",
    "            \"If you are using a custom environment,\\n\"\n",
    "            \"please check it using our env checker:\\n\"\n",
    "            \"https://stable-baselines3.readthedocs.io/en/master/common/env_checker.html.\\n\"\n",
    "            \"If you are using `VecNormalize` or already normalized channel-first images \"\n",
    "            \"you should pass `normalize_images=False`: \\n\"\n",
    "            \"https://stable-baselines3.readthedocs.io/en/master/guide/custom_env.html\"\n",
    "        )\n",
    "        n_input_channels = observation_space.shape[0]\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(n_input_channels, 32, kernel_size=8, stride=4, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "\n",
    "        # Compute shape by doing one forward pass\n",
    "        with th.no_grad():\n",
    "            n_flatten = self.cnn(th.as_tensor(observation_space.sample()[None]).float()).shape[1]\n",
    "\n",
    "        self.linear = nn.Sequential(nn.Linear(n_flatten, features_dim), nn.ReLU())\n",
    "\n",
    "    def forward(self, observations: th.Tensor) -> th.Tensor:\n",
    "        return self.linear(self.cnn(observations))\n",
    "\n",
    "\n",
    "policy_kwargs = dict(\n",
    "    features_extractor_class=CustomCNN,\n",
    "    activation_fn=th.nn.ReLU,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60b3f99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "import pandas as pd\n",
    "\n",
    "class BeforeTrainingCallback(BaseCallback):\n",
    "    def __init__(self, verbose=0):\n",
    "        super(BeforeTrainingCallback, self).__init__(verbose)\n",
    "        self.steps_diff_times = []\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        # This method needs to be implemented but can remain empty if not needed\n",
    "        curr_time = time.time()\n",
    "        self.steps_diff_times.append(curr_time - self.steps_last_diff_time)\n",
    "        self.steps_last_diff_time = curr_time\n",
    "        return True\n",
    "\n",
    "    def _on_rollout_end(self) -> None:\n",
    "        # This method is called before the training process starts after n_steps\n",
    "        env.toggle_pause()\n",
    "        print(\"Rollout has ended, training is about to start.\")\n",
    "        print(\n",
    "            pd.DataFrame.from_dict({\n",
    "                \"step_time\": self.steps_diff_times\n",
    "            }).describe()\n",
    "        )\n",
    "        env.camera.stop_buffer()\n",
    "    \n",
    "    def _on_rollout_start(self) -> None:\n",
    "        print(\"Training has ended!\")\n",
    "        self.steps_last_diff_time = time.time()\n",
    "        env.toggle_pause()\n",
    "\n",
    "# Create the callback\n",
    "callback = BeforeTrainingCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97647bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\my tools\\environments\\pytorch_2_1_0_cuda_11_8\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.num_envs to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.num_envs` for environment variables or `env.get_wrapper_attr('num_envs')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\my tools\\environments\\pytorch_2_1_0_cuda_11_8\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.get_attr to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_attr` for environment variables or `env.get_wrapper_attr('get_attr')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\my tools\\environments\\pytorch_2_1_0_cuda_11_8\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py:77: UserWarning: The `render_mode` attribute is not defined in your environment. It will be set to None.\n",
      "  warnings.warn(\"The `render_mode` attribute is not defined in your environment. It will be set to None.\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from stable_baselines3.common.vec_env import VecNormalize\n",
    "normed_env = VecNormalize(env, norm_reward=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9f16456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RecurrentActorCriticCnnPolicy(\n",
       "  (features_extractor): NatureCNN(\n",
       "    (cnn): Sequential(\n",
       "      (0): Conv2d(1, 32, kernel_size=(8, 8), stride=(4, 4))\n",
       "      (1): ReLU()\n",
       "      (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
       "      (3): ReLU()\n",
       "      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (5): ReLU()\n",
       "      (6): Flatten(start_dim=1, end_dim=-1)\n",
       "    )\n",
       "    (linear): Sequential(\n",
       "      (0): Linear(in_features=2304, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (pi_features_extractor): NatureCNN(\n",
       "    (cnn): Sequential(\n",
       "      (0): Conv2d(1, 32, kernel_size=(8, 8), stride=(4, 4))\n",
       "      (1): ReLU()\n",
       "      (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
       "      (3): ReLU()\n",
       "      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (5): ReLU()\n",
       "      (6): Flatten(start_dim=1, end_dim=-1)\n",
       "    )\n",
       "    (linear): Sequential(\n",
       "      (0): Linear(in_features=2304, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (vf_features_extractor): NatureCNN(\n",
       "    (cnn): Sequential(\n",
       "      (0): Conv2d(1, 32, kernel_size=(8, 8), stride=(4, 4))\n",
       "      (1): ReLU()\n",
       "      (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
       "      (3): ReLU()\n",
       "      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (5): ReLU()\n",
       "      (6): Flatten(start_dim=1, end_dim=-1)\n",
       "    )\n",
       "    (linear): Sequential(\n",
       "      (0): Linear(in_features=2304, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (mlp_extractor): MlpExtractor(\n",
       "    (policy_net): Sequential()\n",
       "    (value_net): Sequential()\n",
       "  )\n",
       "  (action_net): Linear(in_features=256, out_features=2, bias=True)\n",
       "  (value_net): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (lstm_actor): LSTM(512, 256)\n",
       "  (lstm_critic): LSTM(512, 256)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sb3_contrib.common.recurrent.policies import RecurrentActorCriticPolicy, RecurrentActorCriticCnnPolicy\n",
    "from sb3_contrib import RecurrentPPO\n",
    "model = RecurrentPPO(RecurrentActorCriticCnnPolicy, env, verbose=2,\n",
    "    learning_rate=1e-5,\n",
    "    n_steps=2048,\n",
    "    batch_size=128, \n",
    "    clip_range=0.2, \n",
    "    max_grad_norm=0.5,\n",
    "    ent_coef=0.001,\n",
    "    n_epochs=30,\n",
    "    tensorboard_log=\"./ppo_super_mario_tensorboard/\",\n",
    "    #policy_kwargs=policy_kwargs,\n",
    ")\n",
    "model.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e6a010b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load(\"model.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "492b7317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buffer_started\n",
      "Logging to ./ppo_super_mario_tensorboard/RecurrentPPO_30\n",
      "Training has ended!\n",
      "Rollout has ended, training is about to start.\n",
      "          step_time\n",
      "count  36649.000000\n",
      "mean       0.080097\n",
      "std        0.075991\n",
      "min        0.052292\n",
      "25%        0.059020\n",
      "50%        0.069033\n",
      "75%        0.075431\n",
      "max        0.999544\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 56.8     |\n",
      "|    ep_rew_mean     | 3.25     |\n",
      "| time/              |          |\n",
      "|    fps             | 13       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 148      |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\my tools\\environments\\pytorch_2_1_0_cuda_11_8\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.camera to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.camera` for environment variables or `env.get_wrapper_attr('camera')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has ended!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\my tools\\environments\\pytorch_2_1_0_cuda_11_8\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.toggle_pause to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.toggle_pause` for environment variables or `env.get_wrapper_attr('toggle_pause')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buffer_started\n",
      "Rollout has ended, training is about to start.\n",
      "          step_time\n",
      "count  38697.000000\n",
      "mean       0.079684\n",
      "std        0.075817\n",
      "min        0.052278\n",
      "25%        0.057992\n",
      "50%        0.069001\n",
      "75%        0.075022\n",
      "max        0.999544\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 55.4          |\n",
      "|    ep_rew_mean          | 3.04          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 12            |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 330           |\n",
      "|    total_timesteps      | 4096          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00042820312 |\n",
      "|    clip_fraction        | 0.0078        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0542       |\n",
      "|    explained_variance   | 0.976         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | -0.00216      |\n",
      "|    n_updates            | 510           |\n",
      "|    policy_gradient_loss | -0.00122      |\n",
      "|    value_loss           | 0.639         |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\my tools\\environments\\pytorch_2_1_0_cuda_11_8\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.camera to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.camera` for environment variables or `env.get_wrapper_attr('camera')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has ended!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\my tools\\environments\\pytorch_2_1_0_cuda_11_8\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.toggle_pause to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.toggle_pause` for environment variables or `env.get_wrapper_attr('toggle_pause')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buffer_started\n",
      "Rollout has ended, training is about to start.\n",
      "          step_time\n",
      "count  40745.000000\n",
      "mean       0.079310\n",
      "std        0.075715\n",
      "min        0.052278\n",
      "25%        0.057216\n",
      "50%        0.068947\n",
      "75%        0.074346\n",
      "max        0.999544\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 55            |\n",
      "|    ep_rew_mean          | 3.07          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 12            |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 511           |\n",
      "|    total_timesteps      | 6144          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00024860198 |\n",
      "|    clip_fraction        | 0.00462       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0454       |\n",
      "|    explained_variance   | 0.999         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 0.00264       |\n",
      "|    n_updates            | 540           |\n",
      "|    policy_gradient_loss | -0.00211      |\n",
      "|    value_loss           | 0.037         |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\my tools\\environments\\pytorch_2_1_0_cuda_11_8\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.camera to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.camera` for environment variables or `env.get_wrapper_attr('camera')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has ended!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\my tools\\environments\\pytorch_2_1_0_cuda_11_8\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.toggle_pause to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.toggle_pause` for environment variables or `env.get_wrapper_attr('toggle_pause')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buffer_started\n",
      "Rollout has ended, training is about to start.\n",
      "          step_time\n",
      "count  42793.000000\n",
      "mean       0.078958\n",
      "std        0.075557\n",
      "min        0.052218\n",
      "25%        0.056973\n",
      "50%        0.068801\n",
      "75%        0.073017\n",
      "max        0.999544\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 54.5         |\n",
      "|    ep_rew_mean          | 2.95         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 11           |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 692          |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002954253 |\n",
      "|    clip_fraction        | 0.00643      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0374      |\n",
      "|    explained_variance   | 0.988        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 0.00303      |\n",
      "|    n_updates            | 570          |\n",
      "|    policy_gradient_loss | -0.00122     |\n",
      "|    value_loss           | 0.337        |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\my tools\\environments\\pytorch_2_1_0_cuda_11_8\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.camera to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.camera` for environment variables or `env.get_wrapper_attr('camera')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has ended!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\my tools\\environments\\pytorch_2_1_0_cuda_11_8\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.toggle_pause to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.toggle_pause` for environment variables or `env.get_wrapper_attr('toggle_pause')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buffer_started\n",
      "Rollout has ended, training is about to start.\n",
      "          step_time\n",
      "count  44841.000000\n",
      "mean       0.078671\n",
      "std        0.075485\n",
      "min        0.052197\n",
      "25%        0.056593\n",
      "50%        0.068641\n",
      "75%        0.071738\n",
      "max        0.999544\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 54.5         |\n",
      "|    ep_rew_mean          | 2.97         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 11           |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 873          |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010351329 |\n",
      "|    clip_fraction        | 0.000814     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0419      |\n",
      "|    explained_variance   | 0.999        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 0.00244      |\n",
      "|    n_updates            | 600          |\n",
      "|    policy_gradient_loss | -0.00119     |\n",
      "|    value_loss           | 0.0302       |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\my tools\\environments\\pytorch_2_1_0_cuda_11_8\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.camera to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.camera` for environment variables or `env.get_wrapper_attr('camera')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has ended!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\my tools\\environments\\pytorch_2_1_0_cuda_11_8\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.toggle_pause to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.toggle_pause` for environment variables or `env.get_wrapper_attr('toggle_pause')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buffer_started\n",
      "Rollout has ended, training is about to start.\n",
      "          step_time\n",
      "count  46889.000000\n",
      "mean       0.078406\n",
      "std        0.075367\n",
      "min        0.052197\n",
      "25%        0.056491\n",
      "50%        0.068517\n",
      "75%        0.071014\n",
      "max        0.999544\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 55.1        |\n",
      "|    ep_rew_mean          | 3.12        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 11          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 1054        |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027103236 |\n",
      "|    clip_fraction        | 0.0162      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0835     |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | -0.00961    |\n",
      "|    n_updates            | 630         |\n",
      "|    policy_gradient_loss | -0.00591    |\n",
      "|    value_loss           | 0.35        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\my tools\\environments\\pytorch_2_1_0_cuda_11_8\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.camera to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.camera` for environment variables or `env.get_wrapper_attr('camera')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has ended!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\my tools\\environments\\pytorch_2_1_0_cuda_11_8\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.toggle_pause to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.toggle_pause` for environment variables or `env.get_wrapper_attr('toggle_pause')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buffer_started\n",
      "Rollout has ended, training is about to start.\n",
      "          step_time\n",
      "count  48937.000000\n",
      "mean       0.078132\n",
      "std        0.075177\n",
      "min        0.052197\n",
      "25%        0.056320\n",
      "50%        0.068368\n",
      "75%        0.070654\n",
      "max        0.999544\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 55.7         |\n",
      "|    ep_rew_mean          | 3.3          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 11           |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 1236         |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006507237 |\n",
      "|    clip_fraction        | 0.00993      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.134       |\n",
      "|    explained_variance   | 0.888        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 0.169        |\n",
      "|    n_updates            | 660          |\n",
      "|    policy_gradient_loss | -0.00301     |\n",
      "|    value_loss           | 2.77         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\my tools\\environments\\pytorch_2_1_0_cuda_11_8\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.camera to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.camera` for environment variables or `env.get_wrapper_attr('camera')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has ended!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\my tools\\environments\\pytorch_2_1_0_cuda_11_8\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.toggle_pause to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.toggle_pause` for environment variables or `env.get_wrapper_attr('toggle_pause')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buffer_started\n",
      "mario - Snes9x 1.62.3 cannot be minimized.\n"
     ]
    },
    {
     "ename": "StopAsyncIteration",
     "evalue": "Frame buffer is not running",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopAsyncIteration\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m env\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5_000_000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\my tools\\environments\\pytorch_2_1_0_cuda_11_8\\Lib\\site-packages\\sb3_contrib\\ppo_recurrent\\ppo_recurrent.py:454\u001b[0m, in \u001b[0;36mRecurrentPPO.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfRecurrentPPO,\n\u001b[0;32m    447\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    452\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    453\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfRecurrentPPO:\n\u001b[1;32m--> 454\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\my tools\\environments\\pytorch_2_1_0_cuda_11_8\\Lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:300\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    299\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[1;32m--> 300\u001b[0m     continue_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollout_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_rollout_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    302\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m continue_training:\n\u001b[0;32m    303\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\my tools\\environments\\pytorch_2_1_0_cuda_11_8\\Lib\\site-packages\\sb3_contrib\\ppo_recurrent\\ppo_recurrent.py:252\u001b[0m, in \u001b[0;36mRecurrentPPO.collect_rollouts\u001b[1;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space, spaces\u001b[38;5;241m.\u001b[39mBox):\n\u001b[0;32m    250\u001b[0m     clipped_actions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(actions, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mlow, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mhigh)\n\u001b[1;32m--> 252\u001b[0m new_obs, rewards, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclipped_actions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mnum_envs\n\u001b[0;32m    256\u001b[0m \u001b[38;5;66;03m# Give access to local variables\u001b[39;00m\n",
      "File \u001b[1;32mc:\\my tools\\environments\\pytorch_2_1_0_cuda_11_8\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py:206\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[1;34m(self, actions)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;124;03mStep the environments with the given action\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \n\u001b[0;32m    202\u001b[0m \u001b[38;5;124;03m:param actions: the action\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;124;03m:return: observation, reward, done, information\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_async(actions)\n\u001b[1;32m--> 206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\my tools\\environments\\pytorch_2_1_0_cuda_11_8\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py:70\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones[env_idx]:\n\u001b[0;32m     68\u001b[0m         \u001b[38;5;66;03m# save final observation where user can get it, then reset\u001b[39;00m\n\u001b[0;32m     69\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_infos[env_idx][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mterminal_observation\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m obs\n\u001b[1;32m---> 70\u001b[0m         obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_infos[env_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menvs\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_obs(env_idx, obs)\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obs_from_buf(), np\u001b[38;5;241m.\u001b[39mcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_rews), np\u001b[38;5;241m.\u001b[39mcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones), deepcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_infos))\n",
      "File \u001b[1;32mc:\\my tools\\environments\\pytorch_2_1_0_cuda_11_8\\Lib\\site-packages\\stable_baselines3\\common\\monitor.py:83\u001b[0m, in \u001b[0;36mMonitor.reset\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected you to pass keyword argument \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m into reset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_reset_info[key] \u001b[38;5;241m=\u001b[39m value\n\u001b[1;32m---> 83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 24\u001b[0m, in \u001b[0;36mFrameStackingWrapper.reset\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 24\u001b[0m     obs, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;66;03m# self.frames = np.zeros((self.keep_frames, *self.env.observation_space.shape), dtype=np.float32)\u001b[39;00m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;66;03m# for i in range(self.keep_frames):\u001b[39;00m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;66;03m#     self.frames[i] = obs.astype(np.float32) / 255.0 # norm_obs(obs)\u001b[39;00m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;66;03m# stacked_obs = np.array([self.frames[-1-i] for i in range(keep_frames-1, -1, -1) if i % skip_frames==0])\u001b[39;00m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;66;03m# return stacked_obs, info\u001b[39;00m\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], info\n",
      "File \u001b[1;32mc:\\my tools\\environments\\pytorch_2_1_0_cuda_11_8\\Lib\\site-packages\\gymnasium\\wrappers\\order_enforcing.py:61\u001b[0m, in \u001b[0;36mOrderEnforcing.reset\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Resets the environment with `kwargs`.\"\"\"\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\my tools\\environments\\pytorch_2_1_0_cuda_11_8\\Lib\\site-packages\\gymnasium\\wrappers\\env_checker.py:59\u001b[0m, in \u001b[0;36mPassiveEnvChecker.reset\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_reset_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\glucas\\Desktop\\New folder\\super_mario_world-agent\\src\\gamenv\\gameenv.py:102\u001b[0m, in \u001b[0;36mGameEnv.reset\u001b[1;34m(self, seed, options)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# frame buffering\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframe_buffer \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 102\u001b[0m obs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcamera\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_frame_buffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    103\u001b[0m info \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obs, info\n",
      "File \u001b[1;32mc:\\Users\\glucas\\Desktop\\New folder\\super_mario_world-agent\\src\\gamenv\\gamecamera.py:146\u001b[0m, in \u001b[0;36mCameraFrameBuffer.get_frame_buffer\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlock:\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_running:\n\u001b[1;32m--> 146\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopAsyncIteration\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFrame buffer is not running\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    147\u001b[0m     buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframe_buffer\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m buffer\n",
      "\u001b[1;31mStopAsyncIteration\u001b[0m: Frame buffer is not running"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "model.learn(total_timesteps=5_000_000, callback=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8edfdc78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buffer_started\n",
      "mario - Snes9x 1.62.3 cannot be minimized.\n"
     ]
    },
    {
     "ename": "StopAsyncIteration",
     "evalue": "Frame buffer is not running",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopAsyncIteration\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m----> 2\u001b[0m     obs, _ \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n",
      "Cell \u001b[1;32mIn[8], line 24\u001b[0m, in \u001b[0;36mFrameStackingWrapper.reset\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 24\u001b[0m     obs, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;66;03m# self.frames = np.zeros((self.keep_frames, *self.env.observation_space.shape), dtype=np.float32)\u001b[39;00m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;66;03m# for i in range(self.keep_frames):\u001b[39;00m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;66;03m#     self.frames[i] = obs.astype(np.float32) / 255.0 # norm_obs(obs)\u001b[39;00m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;66;03m# stacked_obs = np.array([self.frames[-1-i] for i in range(keep_frames-1, -1, -1) if i % skip_frames==0])\u001b[39;00m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;66;03m# return stacked_obs, info\u001b[39;00m\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], info\n",
      "File \u001b[1;32mc:\\my tools\\environments\\pytorch_2_1_0_cuda_11_8\\Lib\\site-packages\\gymnasium\\wrappers\\order_enforcing.py:61\u001b[0m, in \u001b[0;36mOrderEnforcing.reset\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Resets the environment with `kwargs`.\"\"\"\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\my tools\\environments\\pytorch_2_1_0_cuda_11_8\\Lib\\site-packages\\gymnasium\\wrappers\\env_checker.py:59\u001b[0m, in \u001b[0;36mPassiveEnvChecker.reset\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_reset_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\glucas\\Desktop\\New folder\\super_mario_world-agent\\src\\gamenv\\gameenv.py:102\u001b[0m, in \u001b[0;36mGameEnv.reset\u001b[1;34m(self, seed, options)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# frame buffering\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframe_buffer \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 102\u001b[0m obs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcamera\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_frame_buffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    103\u001b[0m info \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obs, info\n",
      "File \u001b[1;32mc:\\Users\\glucas\\Desktop\\New folder\\super_mario_world-agent\\src\\gamenv\\gamecamera.py:146\u001b[0m, in \u001b[0;36mCameraFrameBuffer.get_frame_buffer\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlock:\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_running:\n\u001b[1;32m--> 146\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopAsyncIteration\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFrame buffer is not running\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    147\u001b[0m     buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframe_buffer\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m buffer\n",
      "\u001b[1;31mStopAsyncIteration\u001b[0m: Frame buffer is not running"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    obs, _ = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        action, _state = model.predict(obs, deterministic=False)\n",
    "        next_obs, reward, done, truncated, info = env.step(action)\n",
    "        obs = next_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68659713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ray.tune.search.optuna import OptunaSearch\n",
    "\n",
    "# from ray.tune.schedulers import ASHAScheduler\n",
    "\n",
    "\n",
    "# config = {\n",
    "#     \"lr\": tune.loguniform(1e-8, 1e-0),\n",
    "#     \"clip_range\": tune.uniform(0.01,0.5),\n",
    "#     \"n_steps\": tune.choice([256, 512, 1028, 2056, 4096]),\n",
    "#     \"batch_size\": tune.choice([32, 64, 128]),\n",
    "#     \"max_grad_norm\": tune.uniform(0.1, 1),\n",
    "#     \"ent_coef\": tune.loguniform(1e-5, 1e-0),\n",
    "#     \"vf_coef\": tune.uniform(0.1, 1),\n",
    "# }\n",
    "\n",
    "# metric = \"avg_reward\"\n",
    "# mode = \"max\"\n",
    "\n",
    "# optuna_search = OptunaSearch(\n",
    "#     metric=metric,\n",
    "#     mode=mode,\n",
    "#     # points_to_evaluate = curr_best_params,\n",
    "# )\n",
    "\n",
    "# asas_scheduler = ASHAScheduler(\n",
    "#     time_attr='training_iteration',\n",
    "#     metric=metric,\n",
    "#     mode=mode,\n",
    "#     max_t=30,\n",
    "#     grace_period=1,\n",
    "#     reduction_factor=3,\n",
    "#     brackets=2\n",
    "# )\n",
    "\n",
    "# trainable_with_resources = tune.with_resources(train_agent, {\"cpu\": 12, \"gpu\": 1})\n",
    "\n",
    "# tuner = tune.Tuner(\n",
    "#     trainable_with_resources,\n",
    "#     tune_config=tune.TuneConfig(\n",
    "#         num_samples=5,\n",
    "#         search_alg=optuna_search,\n",
    "#         scheduler=asas_scheduler\n",
    "#     ),\n",
    "#     param_space=config,\n",
    "# )\n",
    "# results = tuner.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9456e5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Retrieve the environment\n",
    "# env = model.get_env()\n",
    "# Train the agent\n",
    "# model.learn(total_timesteps=100000)\n",
    "# Save the agent\n",
    "\n",
    "model.save(\"model\")\n",
    "# the policy_kwargs are automatically loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c46549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# from sb3_contrib import RecurrentPPO\n",
    "# from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "# from sb3_contrib.common.recurrent.policies import RecurrentActorCriticPolicy\n",
    "\n",
    "# model = RecurrentPPO(\"MlpLstmPolicy\", \"CartPole-v1\", verbose=1)\n",
    "# model.learn(5000)\n",
    "\n",
    "# vec_env = model.get_env()\n",
    "# vec_env.reset()\n",
    "# vec_env.step([vec_env.action_space.sample()])\n",
    "# vec_env.step([vec_env.action_space.sample()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a152a666",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# mean_reward, std_reward = evaluate_policy(model, vec_env, n_eval_episodes=20, warn=False)\n",
    "# print(mean_reward)\n",
    "\n",
    "# model.save(\"ppo_recurrent\")\n",
    "# del model # remove to demonstrate saving and loading\n",
    "\n",
    "# model = RecurrentPPO.load(\"ppo_recurrent\")\n",
    "\n",
    "# obs = vec_env.reset()\n",
    "# # cell and hidden state of the LSTM\n",
    "# lstm_states = None\n",
    "# num_envs = 1\n",
    "# # Episode start signals are used to reset the lstm states\n",
    "# episode_starts = np.ones((num_envs,), dtype=bool)\n",
    "# while True:\n",
    "#     action, lstm_states = model.predict(obs, state=lstm_states, episode_start=episode_starts, deterministic=True)\n",
    "#     obs, rewards, dones, info = vec_env.step(action)\n",
    "#     episode_starts = dones\n",
    "#     vec_env.render(\"human\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
