{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cf2f675-2c27-42a8-b05b-c7b50840ee0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n!pip install mss\\n!pip install matplotlib\\n!pip install tensorboardX python-dotenv\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "!pip install mss\n",
    "!pip install matplotlib\n",
    "!pip install tensorboardX python-dotenv\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03d28b0",
   "metadata": {},
   "source": [
    "## preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6abbb04-bd69-4f55-bb60-83ed10164b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug\n",
    "import time\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93856579",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "EXECUTABLE_NAME = os.getenv('EXECUTABLE_NAME')\n",
    "GAME_WINDOW_NAME = os.getenv('GAME_WINDOW_NAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11af99ca-18a5-405f-8a6e-dfe1d0a674fc",
   "metadata": {},
   "source": [
    "### camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f99a2bed-5bca-4d68-9fef-414956377d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.gamenv import GameEnv\n",
    "\n",
    "game_env = GameEnv(\"snes9x.exe\", \"mario - Snes9x 1.62.3\", (20, 120, -10, -50))\n",
    "camera = game_env.camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ede79e37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 80, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "camera.set_foreground_game()\n",
    "frame = camera.get_frame()\n",
    "plt.imshow(frame)\n",
    "frame.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a1c03cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\my tools\\environments\\pytorch_2_1_0_cuda_11_8\\Lib\\site-packages\\gym\\envs\\registration.py:498: UserWarning: \u001b[33mWARN: Overriding environment CustomGameEnv-v0 already in registry.\u001b[0m\n",
      "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n",
      "c:\\my tools\\environments\\pytorch_2_1_0_cuda_11_8\\Lib\\site-packages\\gym\\utils\\passive_env_checker.py:174: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed a `seed` instead of using `Env.seed` for resetting the environment random number generator.\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\my tools\\environments\\pytorch_2_1_0_cuda_11_8\\Lib\\site-packages\\gym\\utils\\passive_env_checker.py:187: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information.\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\my tools\\environments\\pytorch_2_1_0_cuda_11_8\\Lib\\site-packages\\gym\\utils\\passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n",
      "c:\\my tools\\environments\\pytorch_2_1_0_cuda_11_8\\Lib\\site-packages\\gym\\utils\\passive_env_checker.py:272: UserWarning: \u001b[33mWARN: No render modes was declared in the environment (env.metadata['render_modes'] is None or not defined), you may have trouble when calling `.render()`.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "mario - Snes9x 1.62.3 cannot be minimized.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1000\u001b[39m):  \u001b[38;5;66;03m# Adjust as needed\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     action \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39msample()  \u001b[38;5;66;03m# Replace with your RL agent's action\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m     obs, reward, done, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m     env\u001b[38;5;241m.\u001b[39mrender()\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m done \u001b[38;5;129;01mor\u001b[39;00m truncated:\n",
      "File \u001b[1;32mc:\\my tools\\environments\\pytorch_2_1_0_cuda_11_8\\Lib\\site-packages\\gym\\wrappers\\time_limit.py:50\u001b[0m, in \u001b[0;36mTimeLimit.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[0;32m     40\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Steps through the environment and if the number of steps elapsed exceeds ``max_episode_steps`` then truncate.\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \n\u001b[0;32m     42\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     48\u001b[0m \n\u001b[0;32m     49\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m     observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_episode_steps:\n",
      "File \u001b[1;32mc:\\my tools\\environments\\pytorch_2_1_0_cuda_11_8\\Lib\\site-packages\\gym\\wrappers\\order_enforcing.py:37\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling env.reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\my tools\\environments\\pytorch_2_1_0_cuda_11_8\\Lib\\site-packages\\gym\\wrappers\\env_checker.py:39\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_step_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, action)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\glucas\\Desktop\\New folder\\super_mario_world-agent\\src\\gamenv\\gameenv.py:95\u001b[0m, in \u001b[0;36mGameEnv.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     92\u001b[0m game_over \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m GetForegroundWindow() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcamera\u001b[38;5;241m.\u001b[39mwindow_handle:\n\u001b[1;32m---> 95\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mGetWindowText(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcamera\u001b[38;5;241m.\u001b[39mwindow_handle)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m cannot be minimized.\u001b[39m\u001b[38;5;124m\"\u001b[39m) \n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m#self.toggle_pause()\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;66;03m#print(\"unpaused\")\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;66;03m# self.release_key('right_arrow')\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;66;03m# self.release_key('c')\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelease_key(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mException\u001b[0m: mario - Snes9x 1.62.3 cannot be minimized."
     ]
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "# Register the custom environment with Gym\n",
    "from gym.envs.registration import register\n",
    "\n",
    "register(\n",
    "    id='CustomGameEnv-v0',\n",
    "    entry_point='src.gamenv.gameenv:GameEnv',\n",
    "    max_episode_steps=200,  # Adjust as needed\n",
    ")\n",
    "\n",
    "# Create the environment\n",
    "env = gym.make('CustomGameEnv-v0')\n",
    "\n",
    "obs = env.reset()\n",
    "for _ in range(1000):  # Adjust as needed\n",
    "    action = env.action_space.sample()  # Replace with your RL agent's action\n",
    "    obs, reward, done, truncated, info = env.step(action)\n",
    "    env.render()\n",
    "    if done or truncated:\n",
    "        obs = env.reset()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67adcd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 40_000\n",
    "GAMMA = 0.99\n",
    "LR = 0.00003\n",
    "\n",
    "# NUM_EPISODES = 10000\n",
    "SEQUENCE_LENGTH = 10\n",
    "BATCH_SIZE = 10\n",
    "\n",
    "EPS_NUM_STEPS = 2000\n",
    "EPS_START = 0.05\n",
    "EPS_END = 0.01\n",
    "EPS_DECAY = (EPS_START - EPS_END) / (EPS_NUM_STEPS)\n",
    "\n",
    "action_space = 3 # 4\n",
    "\n",
    "load_model = False\n",
    "model_name = \"2023_12_26_23_13_56\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from itertools import count\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "\n",
    "timestr = time.strftime(\"%Y_%m_%d_%H_%M_%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecd428e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'D' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmemory\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Memory, PrioritizedReplayMemory\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Initiliaze replay memory D to capacity N\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m replay_memory \u001b[38;5;241m=\u001b[39m PrioritizedReplayMemory(\u001b[43mD\u001b[49m, queue_push_thread\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      5\u001b[0m sequence \u001b[38;5;241m=\u001b[39m Memory(SEQUENCE_LENGTH)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'D' is not defined"
     ]
    }
   ],
   "source": [
    "from src.memory import Memory, PrioritizedReplayMemory\n",
    "\n",
    "# Initiliaze replay memory D to capacity N\n",
    "replay_memory = PrioritizedReplayMemory(D, queue_push_thread=True)\n",
    "sequence = Memory(SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be6948b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.batch_model import DQN, phi, PromptQValues\n",
    "from torch import nn\n",
    "\n",
    "# Initialize action-value function Q with random weights\n",
    "\n",
    "lstm_n = 512 #512\n",
    "lstm_layers = 2\n",
    "\n",
    "policy_net = DQN(action_space, lstm_n, lstm_layers).to(device) # used to store teta\n",
    "target_net = DQN(action_space, lstm_n, lstm_layers).to(device) # used to store teta-1\n",
    "\n",
    "if load_model:\n",
    "    policy_net.load_state_dict(torch.load(f'./saved_models/{model_name}/policy_net'))\n",
    "    \n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "optimizer = torch.optim.RMSprop(policy_net.parameters(), lr=LR)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56417fe0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "std evaluated to zero after conversion to torch.float32, leading to division by zero.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m camera\u001b[38;5;241m.\u001b[39mset_foreground_game()\n\u001b[0;32m      2\u001b[0m frame \u001b[38;5;241m=\u001b[39m camera\u001b[38;5;241m.\u001b[39mget_frame()\n\u001b[1;32m----> 3\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mphi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m mean, std \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mmean([\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m]), img\u001b[38;5;241m.\u001b[39mstd([\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m      5\u001b[0m img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[1;32mc:\\Users\\glucas\\Desktop\\New folder\\super_mario_world-agent\\src\\models\\batch_model.py:18\u001b[0m, in \u001b[0;36mphi\u001b[1;34m(observation, device)\u001b[0m\n\u001b[0;32m     16\u001b[0m x \u001b[38;5;241m=\u001b[39m torchvision\u001b[38;5;241m.\u001b[39mtransforms\u001b[38;5;241m.\u001b[39mResize(RESIZE, antialias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(x)\n\u001b[0;32m     17\u001b[0m mean, std \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mmean([\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m]), x\u001b[38;5;241m.\u001b[39mstd([\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m---> 18\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mtorchvision\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransforms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstd\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\my tools\\environments\\pytorch_2_1_0_cuda_11_8\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\my tools\\environments\\pytorch_2_1_0_cuda_11_8\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\my tools\\environments\\pytorch_2_1_0_cuda_11_8\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:277\u001b[0m, in \u001b[0;36mNormalize.forward\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    270\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;124;03m        tensor (Tensor): Tensor image to be normalized.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;124;03m        Tensor: Normalized Tensor image.\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\my tools\\environments\\pytorch_2_1_0_cuda_11_8\\Lib\\site-packages\\torchvision\\transforms\\functional.py:363\u001b[0m, in \u001b[0;36mnormalize\u001b[1;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensor, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m    361\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg should be Tensor Image. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(tensor)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 363\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF_t\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\my tools\\environments\\pytorch_2_1_0_cuda_11_8\\Lib\\site-packages\\torchvision\\transforms\\_functional_tensor.py:923\u001b[0m, in \u001b[0;36mnormalize\u001b[1;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[0;32m    921\u001b[0m std \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mas_tensor(std, dtype\u001b[38;5;241m=\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mtensor\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    922\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (std \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m--> 923\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstd evaluated to zero after conversion to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, leading to division by zero.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    924\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mean\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    925\u001b[0m     mean \u001b[38;5;241m=\u001b[39m mean\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: std evaluated to zero after conversion to torch.float32, leading to division by zero."
     ]
    }
   ],
   "source": [
    "camera.set_foreground_game()\n",
    "frame = camera.get_frame()\n",
    "img = phi(observation=frame, device=device)\n",
    "mean, std = img.mean([1,2]), img.std([1,2])\n",
    "img = img.cpu().numpy()\n",
    "img = img.transpose((1,2,0))\n",
    "print(img.shape)\n",
    "print(mean, std)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, gridspec_kw={'wspace': 0, 'hspace': 0}, dpi=200)\n",
    "axes[0].imshow(img[:,:,0])\n",
    "axes[1].imshow(img[:,:,1])\n",
    "axes[2].imshow(img[:,:,2])\n",
    "for ax in axes.flatten():\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "plt.subplots_adjust(left=0, right=1, top=1, bottom=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdf3413",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assert_sequence(sequence: Memory):\n",
    "    if len(sequence) == SEQUENCE_LENGTH:\n",
    "        sequence_state = sequence.render_simple()\n",
    "        for i in range(len(sequence_state)):\n",
    "            print(f\"{i}\")\n",
    "            plt.imshow(sequence_state[i].cpu().numpy().transpose((1,2,0)))\n",
    "            plt.show()\n",
    "        input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c4361f",
   "metadata": {},
   "outputs": [],
   "source": [
    "global steps\n",
    "steps = 0\n",
    "episode = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cde30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime, threading\n",
    "train_lock = threading.Lock()\n",
    "\n",
    "loss = 0\n",
    "policy_net.train()\n",
    "writer = SummaryWriter(logdir=\"runs/\"+timestr)\n",
    "\n",
    "global thread_running\n",
    "thread_running = False\n",
    "\n",
    "def play():\n",
    "    global thread_running\n",
    "    global steps\n",
    "    episode = 0\n",
    "    epsilon = EPS_START\n",
    "    time.sleep(2)\n",
    "    camera.set_foreground_game()\n",
    "    time.sleep(0.2)\n",
    "    # with SummaryWriter(logdir=\"runs/\"+timestr) as writer:\n",
    "    try:\n",
    "        while steps < D*50-50:\n",
    "            time.sleep(0.1)\n",
    "            with train_lock:\n",
    "                ep_rewards = 0\n",
    "                ep_qvalues = 0\n",
    "                ep_loss = 0\n",
    "                \n",
    "                # Initialise sequence s1 = {x1} and preprocessed sequenced φ1 = φ(s1)\n",
    "                observation = game_env.reset()\n",
    "                state = phi(observation, device)\n",
    "                last_reward = 0\n",
    "                # sequence.clear()\n",
    "\n",
    "                after_act_time = time.perf_counter()\n",
    "                after_start_time_s = time.perf_counter()\n",
    "                \n",
    "                print(thread_running)\n",
    "                if not thread_running:\n",
    "                    return\n",
    "                for t in count():\n",
    "                    elapsed_after_act_time = time.perf_counter() - after_act_time\n",
    "                    after_start_time_s = time.perf_counter()\n",
    "                    step_time_start = time.perf_counter()\n",
    "                    # print(len(sequence), t)\n",
    "\n",
    "                    sequence_render_time = time.perf_counter()\n",
    "                    sequence.push(state)\n",
    "                    sequence_state = sequence.render_simple()\n",
    "                    sequence_render_time = time.perf_counter() - sequence_render_time\n",
    "\n",
    "                    # assert_sequence(sequence)\n",
    "\n",
    "                    predict_time = time.perf_counter()\n",
    "\n",
    "                    with torch.no_grad():\n",
    "                        hn = torch.zeros(lstm_layers, lstm_n, dtype=torch.float32, device=device)\n",
    "                        cn = torch.zeros(lstm_layers, lstm_n, dtype=torch.float32, device=device)\n",
    "                        \n",
    "                        q_value_action, (hn, cn) = policy_net(sequence_state, (hn, cn))\n",
    "                        q_value_action = q_value_action[-1:]\n",
    "                        # prompt_q_values.set_qvalues(q_value_action[0].cpu().numpy())\n",
    "                        q_value_action = q_value_action.max(1)\n",
    "                        \n",
    "                        q_value = q_value_action[0].item()\n",
    "                        ep_qvalues += q_value\n",
    "                    \n",
    "                    predict_time = time.perf_counter() - predict_time\n",
    "                    if predict_time > 0.2:\n",
    "                        print(\"big time\")\n",
    "                    \n",
    "                    # With probability eps select a random action at\n",
    "                    epsilon = epsilon - EPS_DECAY if epsilon > EPS_END else EPS_END\n",
    "                    if random.uniform(0, 1) < epsilon:\n",
    "                        action = torch.tensor([[random.randint(0, action_space-1)]], dtype=torch.long)\n",
    "                    # otherwise select at = maxaQ*(phi(st), a; teta)\n",
    "                    else:\n",
    "                        action = q_value_action[1].view(1,1)\n",
    "                        # print(action)\n",
    "\n",
    "                    # Execute action at in emulator and observe reward rt and image xt+1\n",
    "                    observation, reward, game_over = game_env.step(action.item())\n",
    "                    after_start_time = time.perf_counter() - after_start_time_s\n",
    "                    after_act_time = time.perf_counter()\n",
    "\n",
    "                    ep_rewards += reward\n",
    "                    #print(reward)\n",
    "                    reward = torch.tensor([reward], dtype=torch.float32)\n",
    "\n",
    "                    # Set st+1 = st, at, xt+1 and preprocess phit+1 = phi(st+1)\n",
    "                    if game_over:\n",
    "                        next_state = None # ordem provavelmente errada\n",
    "                    else:\n",
    "                        next_state = phi(observation, device)\n",
    "                        # sequence.push(next_state)\n",
    "                        # rendered, next_sequence_state = sequence.render()\n",
    "\n",
    "                    #if sequence_state != None:\n",
    "                    # replay_memory.push((sequence_state, action, reward, next_sequence_state))\n",
    "                    \n",
    "                    replay_memory.push_queue(state.cpu(), action, reward, next_state.cpu())\n",
    "                    \n",
    "                    # writer\n",
    "                    writer.add_scalar(\"Reward/reward\", reward, steps)\n",
    "                    writer.add_scalar(\"Qvalue/qvalue\", q_value, steps)\n",
    "                    writer.add_scalar(\"Epsilon/epsilon\", epsilon, steps)\n",
    "                    if not game_over:\n",
    "                        writer.add_scalar(\"Steps/Execution_Time\", (time.perf_counter() - step_time_start), steps),\n",
    "                        writer.add_scalar(\"Steps/elapsed_after_act_time\", (elapsed_after_act_time), steps),\n",
    "                        writer.add_scalar(\"Steps/after_start_time\", (after_start_time), steps)\n",
    "                        writer.add_scalar(\"Steps/sequence_render_time\", sequence_render_time, steps)\n",
    "                        writer.add_scalar(\"Steps/predict_time\", predict_time, steps)\n",
    "                        \n",
    "                    writer.flush()\n",
    "                    \n",
    "                    # adding ep log\n",
    "                    ep_rewards += reward\n",
    "\n",
    "                    # sequence_state = next_sequence_state \n",
    "                    state = next_state\n",
    "                    steps += 1\n",
    "                    if game_over:\n",
    "                        \n",
    "                        # ep log\n",
    "                        ep_reward_mean = ep_rewards / (t+1)\n",
    "                        writer.add_scalar(\"Episode/reward_mean\", ep_reward_mean, episode)\n",
    "\n",
    "                        break\n",
    "                episode += 1\n",
    "                # writer.flush()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        thread_running = False\n",
    "    \n",
    "def train():\n",
    "    global thread_running\n",
    "    train_steps = 0\n",
    "    last_play_steps = 0\n",
    "    K = 0\n",
    "\n",
    "    while True:\n",
    "\n",
    "        if not thread_running:\n",
    "            return\n",
    "        \n",
    "        if len(replay_memory) > BATCH_SIZE: # and steps > 200:\n",
    "            with train_lock:\n",
    "                with replay_memory.memory_lock:\n",
    "                    K = ((steps - last_play_steps)) * 2\n",
    "                    last_play_steps = steps\n",
    "                    loss = []\n",
    "                    total_loss = 0\n",
    "                    for k in range(K):\n",
    "                        optimizer.zero_grad()\n",
    "                        clear_output(wait=True)\n",
    "                        print(f\"{k} / {K}\")\n",
    "                        loss.append(policy_net.q_train(target_net, optimizer, loss_fn, replay_memory.sample_sequence(BATCH_SIZE), GAMMA, lstm_n, lstm_layers, replay_memory, device))\n",
    "\n",
    "                        if (k+1) % 10 == 0:\n",
    "                            loss = torch.cat(loss)\n",
    "                            loss = loss.mean()\n",
    "                            loss.backward()\n",
    "                            torch.nn.utils.clip_grad_norm_(policy_net.parameters(), 5.0)\n",
    "                            optimizer.step()\n",
    "                            total_loss += loss.item()\n",
    "                            loss = []\n",
    "                            \n",
    "                    if len(loss) > 0:\n",
    "                        # loss = torch.cat([policy_net.q_train(target_net, optimizer, loss_fn, replay_memory.sample_sequence(BATCH_SIZE), GAMMA, lstm_n, lstm_layers, replay_memory, device) for _ in range(K)])\n",
    "                        loss = torch.cat(loss)\n",
    "                        loss = loss.mean()\n",
    "                        loss.backward()\n",
    "                        torch.nn.utils.clip_grad_norm_(policy_net.parameters(), 5.0)\n",
    "                        optimizer.step()\n",
    "                        total_loss += loss.item()\n",
    "                        clear_output()\n",
    "                    print(f\"total_loss:{total_loss}\")\n",
    "            # ep_loss += loss\n",
    "            writer.add_scalar(\"Loss/loss\", total_loss, train_steps)\n",
    "            \"\"\"\n",
    "            if (t+1) % SEQUENCE_LENGTH == 0:\n",
    "                clear_output(wait=True)\n",
    "                print('loss:', ep_loss, 'step:', steps, 'epsilon:', epsilon, 'last_reward:', ep_rewards, 'ep:', episode)\n",
    "                writer.add_scalar(\"Loss/ep_loss\", ep_loss / SEQUENCE_LENGTH, steps)\n",
    "                writer.add_scalar(\"Reward/ep_rewards\", ep_rewards / SEQUENCE_LENGTH, steps)\n",
    "                writer.add_scalar(\"Qvalue/ep_qvalues\", ep_qvalues / SEQUENCE_LENGTH, steps)\n",
    "                ep_rewards = 0\n",
    "                ep_qvalues = 0\n",
    "                ep_loss = 0\n",
    "            \"\"\"\n",
    "            \"\"\"\n",
    "            if train_steps%100 == 0:\n",
    "                clear_output(wait=True)\n",
    "                print(f\"loss: {loss}\")\n",
    "            \"\"\"\n",
    "            train_steps += 1\n",
    "            if train_steps % 20 == 0:\n",
    "                target_net.load_state_dict(policy_net.state_dict())\n",
    "            time.sleep(0.1)\n",
    "        else:\n",
    "            print(\"dont have sufficient memory to train...\")\n",
    "            time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb10e681",
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_memory.start_queue_thread()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391ca263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_loss:0.1244007358327508\n",
      "threads ended.\n"
     ]
    }
   ],
   "source": [
    "play_thread = threading.Thread(target=play, daemon=True)\n",
    "train_thread = threading.Thread(target=train, daemon=True)\n",
    "\n",
    "thread_running = True\n",
    "\n",
    "play_thread.start()\n",
    "train_thread.start()\n",
    "print(\"threads started...\")\n",
    "\n",
    "play_thread.join()\n",
    "train_thread.join()\n",
    "# replay_memory.thread.join()\n",
    "print(\"threads ended.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44ec2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "(tensor([[[-0.2450, -0.2450, -0.2450,  ..., -0.2450, -0.2450, -0.2450],\n",
      "         [-0.2450, -0.2450, -0.2450,  ..., -0.2450, -0.2450, -0.2450],\n",
      "         [-0.2450, -0.2450, -0.2450,  ..., -0.2450, -0.2450, -0.2450],\n",
      "         ...,\n",
      "         [ 4.3938,  4.3981,  4.3981,  ...,  4.3377,  4.0833,  4.1615],\n",
      "         [ 4.3836,  4.3981,  4.3981,  ...,  4.3395,  4.0931,  4.1708],\n",
      "         [ 4.3869,  4.3981,  4.3981,  ...,  4.3859,  4.3348,  4.3555]],\n",
      "\n",
      "        [[ 0.4148,  0.5830,  0.7602,  ..., -0.6283, -0.5645, -0.3477],\n",
      "         [ 0.6441,  0.8757,  0.8940,  ..., -0.6342, -0.6297, -0.5006],\n",
      "         [ 0.8747,  0.6404,  0.4311,  ..., -0.6342, -0.6338, -0.6164],\n",
      "         ...,\n",
      "         [ 0.8536,  0.8370,  0.8370,  ...,  0.9960,  1.6944,  1.4790],\n",
      "         [ 0.8764,  0.8370,  0.8370,  ...,  0.9926,  1.6790,  1.4651],\n",
      "         [ 0.8682,  0.8370,  0.8370,  ...,  0.8686,  1.0085,  0.9647]],\n",
      "\n",
      "        [[ 1.3233,  1.5560,  1.8015,  ..., -0.2011, -0.0925,  0.2726],\n",
      "         [ 1.6471,  1.9744,  1.9961,  ..., -0.2093, -0.2016,  0.0186],\n",
      "         [ 1.9684,  1.6404,  1.3560,  ..., -0.2093, -0.2086, -0.1764],\n",
      "         ...,\n",
      "         [ 3.7364,  3.7286,  3.7286,  ...,  3.8088,  4.1577,  4.0533],\n",
      "         [ 3.7480,  3.7286,  3.7286,  ...,  3.8069,  4.1491,  4.0460],\n",
      "         [ 3.7427,  3.7286,  3.7286,  ...,  3.7440,  3.8141,  3.7918]]],\n",
      "       device='cuda:0'), tensor([[[-0.2450, -0.2450, -0.2450,  ..., -0.2450, -0.2450, -0.2450],\n",
      "         [-0.2450, -0.2450, -0.2450,  ..., -0.2450, -0.2450, -0.2450],\n",
      "         [-0.2450, -0.2450, -0.2450,  ..., -0.2450, -0.2450, -0.2450],\n",
      "         ...,\n",
      "         [ 4.3938,  4.3981,  4.3981,  ...,  4.3377,  4.0833,  4.1615],\n",
      "         [ 4.3836,  4.3981,  4.3981,  ...,  4.3395,  4.0931,  4.1708],\n",
      "         [ 4.3869,  4.3981,  4.3981,  ...,  4.3859,  4.3348,  4.3555]],\n",
      "\n",
      "        [[ 0.4148,  0.5830,  0.7602,  ..., -0.6283, -0.5645, -0.3477],\n",
      "         [ 0.6441,  0.8757,  0.8940,  ..., -0.6342, -0.6297, -0.5006],\n",
      "         [ 0.8747,  0.6404,  0.4311,  ..., -0.6342, -0.6338, -0.6164],\n",
      "         ...,\n",
      "         [ 0.8536,  0.8370,  0.8370,  ...,  0.9960,  1.6944,  1.4790],\n",
      "         [ 0.8764,  0.8370,  0.8370,  ...,  0.9926,  1.6790,  1.4651],\n",
      "         [ 0.8682,  0.8370,  0.8370,  ...,  0.8686,  1.0085,  0.9647]],\n",
      "\n",
      "        [[ 1.3233,  1.5560,  1.8015,  ..., -0.2011, -0.0925,  0.2726],\n",
      "         [ 1.6471,  1.9744,  1.9961,  ..., -0.2093, -0.2016,  0.0186],\n",
      "         [ 1.9684,  1.6404,  1.3560,  ..., -0.2093, -0.2086, -0.1764],\n",
      "         ...,\n",
      "         [ 3.7364,  3.7286,  3.7286,  ...,  3.8088,  4.1577,  4.0533],\n",
      "         [ 3.7480,  3.7286,  3.7286,  ...,  3.8069,  4.1491,  4.0460],\n",
      "         [ 3.7427,  3.7286,  3.7286,  ...,  3.7440,  3.8141,  3.7918]]],\n",
      "       device='cuda:0'), tensor([[[-0.2448, -0.2448, -0.2448,  ..., -0.2448, -0.2448, -0.2448],\n",
      "         [-0.2448, -0.2448, -0.2448,  ..., -0.2448, -0.2448, -0.2448],\n",
      "         [-0.2448, -0.2448, -0.2448,  ..., -0.2448, -0.2448, -0.2448],\n",
      "         ...,\n",
      "         [ 4.3978,  4.4022,  4.4022,  ...,  4.3417,  4.0871,  4.1654],\n",
      "         [ 4.3876,  4.4022,  4.4022,  ...,  4.3435,  4.0969,  4.1747],\n",
      "         [ 4.3909,  4.4022,  4.4022,  ...,  4.3899,  4.3388,  4.3595]],\n",
      "\n",
      "        [[ 0.4127,  0.5806,  0.7574,  ..., -0.6286, -0.5650, -0.3485],\n",
      "         [ 0.6415,  0.8728,  0.8911,  ..., -0.6345, -0.6300, -0.5012],\n",
      "         [ 0.8718,  0.6379,  0.4289,  ..., -0.6345, -0.6342, -0.6168],\n",
      "         ...,\n",
      "         [ 0.8507,  0.8342,  0.8342,  ...,  0.9928,  1.6901,  1.4750],\n",
      "         [ 0.8735,  0.8341,  0.8342,  ...,  0.9894,  1.6747,  1.4612],\n",
      "         [ 0.8653,  0.8341,  0.8342,  ...,  0.8657,  1.0054,  0.9616]],\n",
      "\n",
      "        [[ 1.3233,  1.5560,  1.8016,  ..., -0.2014, -0.0927,  0.2724],\n",
      "         [ 1.6471,  1.9745,  1.9962,  ..., -0.2096, -0.2019,  0.0184],\n",
      "         [ 1.9685,  1.6405,  1.3560,  ..., -0.2096, -0.2089, -0.1767],\n",
      "         ...,\n",
      "         [ 3.7367,  3.7290,  3.7290,  ...,  3.8092,  4.1582,  4.0537],\n",
      "         [ 3.7484,  3.7290,  3.7290,  ...,  3.8074,  4.1495,  4.0465],\n",
      "         [ 3.7431,  3.7290,  3.7290,  ...,  3.7444,  3.8145,  3.7922]]],\n",
      "       device='cuda:0'), tensor([[[-0.2450, -0.2450, -0.2450,  ..., -0.2450, -0.2450, -0.2450],\n",
      "         [-0.2450, -0.2450, -0.2450,  ..., -0.2450, -0.2450, -0.2450],\n",
      "         [-0.2450, -0.2450, -0.2450,  ..., -0.2450, -0.2450, -0.2450],\n",
      "         ...,\n",
      "         [ 4.3938,  4.3981,  4.3981,  ...,  4.3377,  4.0833,  4.1615],\n",
      "         [ 4.3836,  4.3981,  4.3981,  ...,  4.3395,  4.0931,  4.1708],\n",
      "         [ 4.3869,  4.3981,  4.3981,  ...,  4.3859,  4.3348,  4.3555]],\n",
      "\n",
      "        [[ 0.4148,  0.5830,  0.7602,  ..., -0.6283, -0.5645, -0.3477],\n",
      "         [ 0.6441,  0.8757,  0.8940,  ..., -0.6342, -0.6297, -0.5006],\n",
      "         [ 0.8747,  0.6404,  0.4311,  ..., -0.6342, -0.6338, -0.6164],\n",
      "         ...,\n",
      "         [ 0.8536,  0.8370,  0.8370,  ...,  0.9960,  1.6944,  1.4790],\n",
      "         [ 0.8764,  0.8370,  0.8370,  ...,  0.9926,  1.6790,  1.4651],\n",
      "         [ 0.8682,  0.8370,  0.8370,  ...,  0.8686,  1.0085,  0.9647]],\n",
      "\n",
      "        [[ 1.3233,  1.5560,  1.8015,  ..., -0.2011, -0.0925,  0.2726],\n",
      "         [ 1.6471,  1.9744,  1.9961,  ..., -0.2093, -0.2016,  0.0186],\n",
      "         [ 1.9684,  1.6404,  1.3560,  ..., -0.2093, -0.2086, -0.1764],\n",
      "         ...,\n",
      "         [ 3.7364,  3.7286,  3.7286,  ...,  3.8088,  4.1577,  4.0533],\n",
      "         [ 3.7480,  3.7286,  3.7286,  ...,  3.8069,  4.1491,  4.0460],\n",
      "         [ 3.7427,  3.7286,  3.7286,  ...,  3.7440,  3.8141,  3.7918]]],\n",
      "       device='cuda:0'), tensor([[[-0.2448, -0.2448, -0.2448,  ..., -0.2448, -0.2448, -0.2448],\n",
      "         [-0.2448, -0.2448, -0.2448,  ..., -0.2448, -0.2448, -0.2448],\n",
      "         [-0.2448, -0.2448, -0.2448,  ..., -0.2448, -0.2448, -0.2448],\n",
      "         ...,\n",
      "         [ 4.3980,  4.4023,  4.4023,  ...,  4.3419,  4.0873,  4.1656],\n",
      "         [ 4.3878,  4.4023,  4.4023,  ...,  4.3437,  4.0970,  4.1748],\n",
      "         [ 4.3911,  4.4023,  4.4023,  ...,  4.3901,  4.3390,  4.3597]],\n",
      "\n",
      "        [[ 0.4126,  0.5805,  0.7572,  ..., -0.6282, -0.5645, -0.3482],\n",
      "         [ 0.6414,  0.8724,  0.8907,  ..., -0.6341, -0.6295, -0.5007],\n",
      "         [ 0.8715,  0.6377,  0.4289,  ..., -0.6341, -0.6337, -0.6163],\n",
      "         ...,\n",
      "         [ 0.8504,  0.8339,  0.8339,  ...,  0.9924,  1.6893,  1.4744],\n",
      "         [ 0.8732,  0.8338,  0.8339,  ...,  0.9891,  1.6739,  1.4606],\n",
      "         [ 0.8650,  0.8338,  0.8339,  ...,  0.8654,  1.0050,  0.9612]],\n",
      "\n",
      "        [[ 1.3241,  1.5570,  1.8026,  ..., -0.2013, -0.0926,  0.2728],\n",
      "         [ 1.6481,  1.9756,  1.9973,  ..., -0.2095, -0.2018,  0.0185],\n",
      "         [ 1.9696,  1.6414,  1.3568,  ..., -0.2095, -0.2088, -0.1766],\n",
      "         ...,\n",
      "         [ 3.7387,  3.7309,  3.7309,  ...,  3.8112,  4.1604,  4.0558],\n",
      "         [ 3.7503,  3.7309,  3.7309,  ...,  3.8093,  4.1517,  4.0486],\n",
      "         [ 3.7450,  3.7309,  3.7309,  ...,  3.7463,  3.8165,  3.7942]]],\n",
      "       device='cuda:0'))\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# sequence_state = sequence.render_simple()\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(sequence_state[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m----> 6\u001b[0m \u001b[43mprompt_conv\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequence_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\glucas\\Documents\\a\\repos\\random-things-i-do\\reinforcement-learning\\super_mario_world-agent\\src\\models\\batch_model.py:46\u001b[0m, in \u001b[0;36mprompt_conv\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprompt_conv\u001b[39m(x):\n\u001b[1;32m---> 46\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m)\n\u001b[0;32m     47\u001b[0m     x \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mlen\u001b[39m(x)) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m : \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "from src.models.batch_model import prompt_conv\n",
    "sequence_state = replay_memory.sample_sequence(5)\n",
    "print(len(sequence_state[0]))\n",
    "# sequence_state = sequence.render_simple()\n",
    "print(sequence_state[0])\n",
    "prompt_conv(sequence_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d37d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "save_model_dir = './saved_models'\n",
    "\n",
    "if not os.path.exists(f'{save_model_dir}'):\n",
    "    os.mkdir(f'{save_model_dir}')\n",
    "if not os.path.exists(f'{save_model_dir}/{timestr}'):\n",
    "    os.mkdir(f'{save_model_dir}/{timestr}')\n",
    "\n",
    "torch.save(policy_net.state_dict(), f'{save_model_dir}/{timestr}/policy_net')\n",
    "torch.save(target_net.state_dict(), f'{save_model_dir}/{timestr}/target_net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de48566",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assert_memory():\n",
    "    sequence = replay_memory.sample_sequence(3)\n",
    "\n",
    "    states, actions, rewards, next_states = *zip(*sequence), # let the ',' to not give syntax error\n",
    "    sequence_length = len(states) # - 1\n",
    "\n",
    "    states = torch.stack(states)\n",
    "    actions = torch.cat(actions)\n",
    "    rewards = torch.cat(rewards)\n",
    "\n",
    "    non_final_states_mask = torch.tensor(tuple(map(lambda s: s is not None, next_states)), device=device)\n",
    "    non_final_next_states = torch.stack([s for s in next_states if s is not None])\n",
    "\n",
    "    print(len(states))\n",
    "    for i in range(len(states)):\n",
    "        print(f\"{i}\")\n",
    "        plt.imshow(states[i].cpu().numpy().transpose((1,2,0)))\n",
    "        plt.show()\n",
    "        plt.imshow(non_final_next_states[i].cpu().numpy().transpose((1,2,0)))\n",
    "        plt.show()\n",
    "assert_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b979210",
   "metadata": {},
   "outputs": [],
   "source": [
    "exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.set_foreground_game()\n",
    "\n",
    "policy_net.eval()\n",
    "while True:\n",
    "    observation = game_env.reset()\n",
    "    time.sleep(0.1)\n",
    "    state = phi(observation, device)\n",
    "    sequence.clear()\n",
    "    \n",
    "    for t in count():\n",
    "\n",
    "        sequence.push(state)\n",
    "        rendered = sequence.render_simple()\n",
    "\n",
    "        hn = torch.zeros(lstm_layers, lstm_n, dtype=torch.float32, device=device)\n",
    "        cn = torch.zeros(lstm_layers, lstm_n, dtype=torch.float32, device=device)\n",
    "        with torch.no_grad():\n",
    "            q_value_action, (hn, cn) = policy_net.forward_prompt(rendered, (hn, cn))\n",
    "            q_value_action = q_value_action[-1:]\n",
    "            print(q_value_action, end=\"\")\n",
    "            q_value_action = q_value_action.max(1)\n",
    "            action = q_value_action[1].view(1,1)\n",
    "            print(f\", actions {action}\")\n",
    "\n",
    "        observation, reward, game_over = game_env.step(action.item())\n",
    "        if game_over:\n",
    "            next_state = None # ordem provavelmente errada\n",
    "        else:\n",
    "            next_state = phi(observation, device)\n",
    "        state = next_state\n",
    "        if game_over:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15899787",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"camera.set_foreground_game()\n",
    "state = phi(camera.get_frame(), device)\n",
    "\n",
    "policy_net.eval()\n",
    "hn = torch.zeros(lstm_layers, lstm_n, dtype=torch.float32, device=device)\n",
    "cn = torch.zeros(lstm_layers, lstm_n, dtype=torch.float32, device=device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    q_value_action, (hn, cn) = policy_net(state.unsqueeze(0), (hn, cn))\n",
    "    q_value_action = q_value_action[-1:]\n",
    "    print(q_value_action)\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
