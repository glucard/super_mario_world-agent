{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cf2f675-2c27-42a8-b05b-c7b50840ee0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n!pip install mss\\n!pip install matplotlib\\n!pip install tensorboardX python-dotenv\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "!pip install mss\n",
    "!pip install matplotlib\n",
    "!pip install tensorboardX python-dotenv\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03d28b0",
   "metadata": {},
   "source": [
    "## preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6abbb04-bd69-4f55-bb60-83ed10164b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug\n",
    "import time\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93856579",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "EXECUTABLE_NAME = os.getenv('EXECUTABLE_NAME')\n",
    "GAME_WINDOW_NAME = os.getenv('GAME_WINDOW_NAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11af99ca-18a5-405f-8a6e-dfe1d0a674fc",
   "metadata": {},
   "source": [
    "### camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f99a2bed-5bca-4d68-9fef-414956377d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.gamenv import GameEnv\n",
    "\n",
    "game_env = GameEnv(\"snes9x.exe\", \"mario - Snes9x 1.62.3\", (20, 120, -10, -50))\n",
    "camera = game_env.camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ede79e37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 80, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "camera.set_foreground_game()\n",
    "frame = camera.get_frame()\n",
    "plt.imshow(frame)\n",
    "frame.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a1c03cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium\n",
    "\n",
    "# Register the custom environment with Gym\n",
    "from gymnasium.envs.registration import register\n",
    "\n",
    "register(\n",
    "    id='CustomGameEnv-v0',\n",
    "    entry_point='src.gamenv.gameenv:GameEnv',\n",
    "    max_episode_steps=None,  # Adjust as needed\n",
    ")\n",
    "\n",
    "# Create the environment\n",
    "# env = gymnasium.make('CustomGameEnv-v0')\n",
    "\n",
    "# obs = env.reset()\n",
    "# for _ in range(500):  # Adjust as needed\n",
    "#     action = env.action_space.sample()  # Replace with your RL agent's action\n",
    "#     obs, reward, done, truncated, info = env.step(action)\n",
    "#     env.render()\n",
    "#     if done or truncated:\n",
    "#         obs = env.reset()\n",
    "# env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2b0bc71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\my tools\\environments\\pytorch_2_1_0_cuda_11_8\\Lib\\site-packages\\gymnasium\\envs\\registration.py:481: UserWarning: \u001b[33mWARN: The environment creator metadata doesn't include `render_modes`, contains: ['render.modes']\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "import gymnasium\n",
    "import numpy as np\n",
    "from gymnasium import spaces\n",
    "\n",
    "env = gymnasium.make('CustomGameEnv-v0')\n",
    "n_stack = 30  # Number of frames to stack\n",
    "\n",
    "class FrameStackingWrapper(gymnasium.Wrapper):\n",
    "    def __init__(self, env, n_stack=4):\n",
    "        super(FrameStackingWrapper, self).__init__(env)\n",
    "        self.n_stack = n_stack\n",
    "        self.frames = np.zeros((n_stack, *env.observation_space.shape), dtype=np.uint8)\n",
    "        \n",
    "        self.observation_space = spaces.Box(low=0, high=255, shape=(n_stack, 80, 80, 3), dtype=np.uint8)\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        obs, info = self.env.reset(**kwargs)\n",
    "        self.frames = np.zeros((self.n_stack, *self.env.observation_space.shape), dtype=np.uint8)\n",
    "        for i in range(self.n_stack):\n",
    "            self.frames[i] = obs\n",
    "        stacked_obs = np.array(self.frames)\n",
    "        return stacked_obs, info\n",
    "\n",
    "    def step(self, action):\n",
    "        obs, reward, done, truncated, info = self.env.step(action)\n",
    "        self.frames[:-1] = self.frames[1:]  # Shift frames\n",
    "        self.frames[-1] = obs  # Add new frame\n",
    "        stacked_obs = np.array(self.frames)\n",
    "        return stacked_obs, reward, done, truncated, info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64c4ecb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env.vec_frame_stack import VecFrameStack\n",
    "\n",
    "env = FrameStackingWrapper(env, n_stack=n_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b48af930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\my tools\\environments\\pytorch_2_1_0_cuda_11_8\\Lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:155: UserWarning: You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 1048`, after every 16 untruncated mini-batches, there will be a truncated mini-batch of size 24\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=1048 and n_envs=1)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "\n",
    "\n",
    "class CustomCNN(BaseFeaturesExtractor):\n",
    "    \"\"\"\n",
    "    :param observation_space: (gym.Space)\n",
    "    :param features_dim: (int) Number of features extracted.\n",
    "        This corresponds to the number of unit for the last layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, observation_space: gym.spaces.Box, features_dim: int = 256):\n",
    "        super(CustomCNN, self).__init__(observation_space, features_dim)\n",
    "        # We assume CxHxW images (channels first)\n",
    "        # Re-ordering will be done by pre-preprocessing or wrapper\n",
    "        n_input_channels = observation_space.shape[-1]\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(n_input_channels, 32, kernel_size=8, stride=4, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "\n",
    "        # Compute shape by doing one forward pass\n",
    "        with th.no_grad():\n",
    "            n_flatten = self.cnn(\n",
    "                th.as_tensor(observation_space.sample()).permute(0,3,1,2).float()\n",
    "            ).shape[1]\n",
    "        self.lstm = nn.LSTM(input_size=n_flatten, hidden_size=features_dim, num_layers=1, batch_first=True)\n",
    "\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(features_dim, features_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, observations: th.Tensor) -> th.Tensor:\n",
    "        x = observations.permute(0,1,4,2,3)\n",
    "        batch_size, seq_len, c, h, w = x.size()\n",
    "\n",
    "        x = observations.view(batch_size * seq_len, c, h, w)\n",
    "        cnn_out = self.cnn(x)\n",
    "        cnn_out = cnn_out.view(batch_size, seq_len, -1)\n",
    "        lstm_out, (h_n, c_n) = self.lstm(cnn_out)\n",
    "        lstm_out = F.relu(lstm_out[:,-1,:])\n",
    "        return self.linear(lstm_out)\n",
    "\n",
    "policy_kwargs = dict(\n",
    "    features_extractor_class=CustomCNN,\n",
    "    features_extractor_kwargs=dict(features_dim=256),\n",
    ")\n",
    "\n",
    "model = PPO('MlpPolicy', env, verbose=2,\n",
    "            learning_rate=5e-3,\n",
    "            n_steps=1048,\n",
    "            batch_size=64, \n",
    "            clip_range=0.2, \n",
    "            max_grad_norm=0.5,\n",
    "            tensorboard_log=\"./ppo_super_mario_tensorboard/\",\n",
    "            policy_kwargs=policy_kwargs,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cde987bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ActorCriticPolicy(\n",
       "  (features_extractor): CustomCNN(\n",
       "    (cnn): Sequential(\n",
       "      (0): Conv2d(3, 32, kernel_size=(8, 8), stride=(4, 4))\n",
       "      (1): ReLU()\n",
       "      (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
       "      (3): ReLU()\n",
       "      (4): Flatten(start_dim=1, end_dim=-1)\n",
       "    )\n",
       "    (lstm): LSTM(4096, 256, batch_first=True)\n",
       "    (linear): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (pi_features_extractor): CustomCNN(\n",
       "    (cnn): Sequential(\n",
       "      (0): Conv2d(3, 32, kernel_size=(8, 8), stride=(4, 4))\n",
       "      (1): ReLU()\n",
       "      (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
       "      (3): ReLU()\n",
       "      (4): Flatten(start_dim=1, end_dim=-1)\n",
       "    )\n",
       "    (lstm): LSTM(4096, 256, batch_first=True)\n",
       "    (linear): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (vf_features_extractor): CustomCNN(\n",
       "    (cnn): Sequential(\n",
       "      (0): Conv2d(3, 32, kernel_size=(8, 8), stride=(4, 4))\n",
       "      (1): ReLU()\n",
       "      (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
       "      (3): ReLU()\n",
       "      (4): Flatten(start_dim=1, end_dim=-1)\n",
       "    )\n",
       "    (lstm): LSTM(4096, 256, batch_first=True)\n",
       "    (linear): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (mlp_extractor): MlpExtractor(\n",
       "    (policy_net): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=64, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (3): Tanh()\n",
       "    )\n",
       "    (value_net): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=64, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (3): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (action_net): Linear(in_features=64, out_features=6, bias=True)\n",
       "  (value_net): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60b3f99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "class BeforeTrainingCallback(BaseCallback):\n",
    "    def __init__(self, verbose=0):\n",
    "        super(BeforeTrainingCallback, self).__init__(verbose)\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        # This method needs to be implemented but can remain empty if not needed\n",
    "        return True\n",
    "\n",
    "    def _on_rollout_end(self) -> None:\n",
    "        # This method is called before the training process starts after n_steps\n",
    "        print(\"Rollout has ended, training is about to start.\")\n",
    "        env.toggle_pause()\n",
    "    \n",
    "    def _on_rollout_start(self) -> None:\n",
    "        print(\"Training has ended!\")\n",
    "        env.toggle_pause()\n",
    "\n",
    "# Create the callback\n",
    "callback = BeforeTrainingCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9f16456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./ppo_super_mario_tensorboard/PPO_61\n",
      "Training has ended!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\my tools\\environments\\pytorch_2_1_0_cuda_11_8\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.toggle_pause to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.toggle_pause` for environment variables or `env.get_wrapper_attr('toggle_pause')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rollout has ended, training is about to start.\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 34   |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 30   |\n",
      "|    total_timesteps | 1048 |\n",
      "-----------------------------\n",
      "Training has ended!\n",
      "Rollout has ended, training is about to start.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 515         |\n",
      "|    ep_rew_mean          | 1.77        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 75          |\n",
      "|    total_timesteps      | 2096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010054373 |\n",
      "|    clip_fraction        | 0.265       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.18       |\n",
      "|    explained_variance   | -0.0213     |\n",
      "|    learning_rate        | 0.005       |\n",
      "|    loss                 | 0.115       |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    value_loss           | 0.582       |\n",
      "-----------------------------------------\n",
      "Training has ended!\n",
      "Rollout has ended, training is about to start.\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 338          |\n",
      "|    ep_rew_mean          | 3.44         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 25           |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 120          |\n",
      "|    total_timesteps      | 3144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075603346 |\n",
      "|    clip_fraction        | 0.121        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.16        |\n",
      "|    explained_variance   | 0.000374     |\n",
      "|    learning_rate        | 0.005        |\n",
      "|    loss                 | 0.665        |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00432     |\n",
      "|    value_loss           | 1.09         |\n",
      "------------------------------------------\n",
      "Training has ended!\n",
      "Rollout has ended, training is about to start.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 259         |\n",
      "|    ep_rew_mean          | 4.21        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 25          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 167         |\n",
      "|    total_timesteps      | 4192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011232811 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.12       |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.005       |\n",
      "|    loss                 | 0.271       |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00815    |\n",
      "|    value_loss           | 1.65        |\n",
      "-----------------------------------------\n",
      "Training has ended!\n",
      "Rollout has ended, training is about to start.\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 227        |\n",
      "|    ep_rew_mean          | 4.54       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 24         |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 213        |\n",
      "|    total_timesteps      | 5240       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01047327 |\n",
      "|    clip_fraction        | 0.068      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.08      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.005      |\n",
      "|    loss                 | 0.74       |\n",
      "|    n_updates            | 40         |\n",
      "|    policy_gradient_loss | -0.00399   |\n",
      "|    value_loss           | 2.5        |\n",
      "----------------------------------------\n",
      "Training has ended!\n",
      "Rollout has ended, training is about to start.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 208         |\n",
      "|    ep_rew_mean          | 4.64        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 24          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 259         |\n",
      "|    total_timesteps      | 6288        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009222414 |\n",
      "|    clip_fraction        | 0.0456      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.05       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.005       |\n",
      "|    loss                 | 2.63        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.00212    |\n",
      "|    value_loss           | 2.77        |\n",
      "-----------------------------------------\n",
      "Training has ended!\n",
      "Rollout has ended, training is about to start.\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 207          |\n",
      "|    ep_rew_mean          | 5.45         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 24           |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 305          |\n",
      "|    total_timesteps      | 7336         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0122436145 |\n",
      "|    clip_fraction        | 0.122        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.95        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.005        |\n",
      "|    loss                 | 1.87         |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.00644     |\n",
      "|    value_loss           | 2.71         |\n",
      "------------------------------------------\n",
      "Training has ended!\n",
      "Rollout has ended, training is about to start.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 195         |\n",
      "|    ep_rew_mean          | 5.25        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 23          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 352         |\n",
      "|    total_timesteps      | 8384        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015916066 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.92       |\n",
      "|    explained_variance   | 6.51e-05    |\n",
      "|    learning_rate        | 0.005       |\n",
      "|    loss                 | 1.01        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00581    |\n",
      "|    value_loss           | 2.48        |\n",
      "-----------------------------------------\n",
      "Training has ended!\n",
      "Rollout has ended, training is about to start.\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 196          |\n",
      "|    ep_rew_mean          | 5.73         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 23           |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 397          |\n",
      "|    total_timesteps      | 9432         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069722957 |\n",
      "|    clip_fraction        | 0.097        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.9         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.005        |\n",
      "|    loss                 | 3.79         |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.00363     |\n",
      "|    value_loss           | 3.92         |\n",
      "------------------------------------------\n",
      "Training has ended!\n",
      "Rollout has ended, training is about to start.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 188         |\n",
      "|    ep_rew_mean          | 5.56        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 23          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 443         |\n",
      "|    total_timesteps      | 10480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012982892 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.79       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.005       |\n",
      "|    loss                 | 1.47        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00986    |\n",
      "|    value_loss           | 2.75        |\n",
      "-----------------------------------------\n",
      "Training has ended!\n",
      "Rollout has ended, training is about to start.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 192         |\n",
      "|    ep_rew_mean          | 6.13        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 23          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 488         |\n",
      "|    total_timesteps      | 11528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008485624 |\n",
      "|    clip_fraction        | 0.094       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.7        |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.005       |\n",
      "|    loss                 | 2.24        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0065     |\n",
      "|    value_loss           | 3.87        |\n",
      "-----------------------------------------\n",
      "Training has ended!\n",
      "Rollout has ended, training is about to start.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 197         |\n",
      "|    ep_rew_mean          | 6.66        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 23          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 532         |\n",
      "|    total_timesteps      | 12576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009637395 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.74       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.005       |\n",
      "|    loss                 | 1.69        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00544    |\n",
      "|    value_loss           | 3.01        |\n",
      "-----------------------------------------\n",
      "Training has ended!\n",
      "Rollout has ended, training is about to start.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 188         |\n",
      "|    ep_rew_mean          | 6.32        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 23          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 579         |\n",
      "|    total_timesteps      | 13624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014262723 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.64       |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.005       |\n",
      "|    loss                 | 0.168       |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00557    |\n",
      "|    value_loss           | 1.89        |\n",
      "-----------------------------------------\n",
      "Training has ended!\n",
      "Rollout has ended, training is about to start.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 183         |\n",
      "|    ep_rew_mean          | 6.24        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 23          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 626         |\n",
      "|    total_timesteps      | 14672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010257096 |\n",
      "|    clip_fraction        | 0.0551      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.55       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.005       |\n",
      "|    loss                 | 3.17        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.000262   |\n",
      "|    value_loss           | 4.93        |\n",
      "-----------------------------------------\n",
      "Training has ended!\n",
      "Rollout has ended, training is about to start.\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 183          |\n",
      "|    ep_rew_mean          | 6.34         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 23           |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 670          |\n",
      "|    total_timesteps      | 15720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073065185 |\n",
      "|    clip_fraction        | 0.0544       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.005        |\n",
      "|    loss                 | 1.63         |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.00202     |\n",
      "|    value_loss           | 4.51         |\n",
      "------------------------------------------\n",
      "Training has ended!\n",
      "Rollout has ended, training is about to start.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 195         |\n",
      "|    ep_rew_mean          | 7.42        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 23          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 714         |\n",
      "|    total_timesteps      | 16768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004659803 |\n",
      "|    clip_fraction        | 0.0462      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.005       |\n",
      "|    loss                 | 0.878       |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.00133    |\n",
      "|    value_loss           | 2.7         |\n",
      "-----------------------------------------\n",
      "Training has ended!\n",
      "Rollout has ended, training is about to start.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 197         |\n",
      "|    ep_rew_mean          | 7.63        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 23          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 757         |\n",
      "|    total_timesteps      | 17816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010902328 |\n",
      "|    clip_fraction        | 0.0774      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.005       |\n",
      "|    loss                 | 0.224       |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.00165    |\n",
      "|    value_loss           | 0.916       |\n",
      "-----------------------------------------\n",
      "Training has ended!\n",
      "Rollout has ended, training is about to start.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 207         |\n",
      "|    ep_rew_mean          | 8.84        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 23          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 803         |\n",
      "|    total_timesteps      | 18864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004628471 |\n",
      "|    clip_fraction        | 0.0604      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.005       |\n",
      "|    loss                 | 0.0501      |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | 0.000327    |\n",
      "|    value_loss           | 1.01        |\n",
      "-----------------------------------------\n",
      "Training has ended!\n",
      "Rollout has ended, training is about to start.\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 210          |\n",
      "|    ep_rew_mean          | 9.26         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 23           |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 847          |\n",
      "|    total_timesteps      | 19912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064879847 |\n",
      "|    clip_fraction        | 0.0892       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.4         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.005        |\n",
      "|    loss                 | 4.03         |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.00312     |\n",
      "|    value_loss           | 4.15         |\n",
      "------------------------------------------\n",
      "Training has ended!\n",
      "Rollout has ended, training is about to start.\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 218          |\n",
      "|    ep_rew_mean          | 10.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 23           |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 891          |\n",
      "|    total_timesteps      | 20960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063136066 |\n",
      "|    clip_fraction        | 0.0685       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.39        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.005        |\n",
      "|    loss                 | 1.29         |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.0037      |\n",
      "|    value_loss           | 2.85         |\n",
      "------------------------------------------\n",
      "Training has ended!\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "mario - Snes9x 1.62.3 cannot be minimized.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model with the custom callback\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\my tools\\environments\\pytorch_2_1_0_cuda_11_8\\Lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:315\u001b[0m, in \u001b[0;36mPPO.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    307\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfPPO,\n\u001b[0;32m    308\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    313\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    314\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfPPO:\n\u001b[1;32m--> 315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\my tools\\environments\\pytorch_2_1_0_cuda_11_8\\Lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:300\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    299\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[1;32m--> 300\u001b[0m     continue_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollout_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_rollout_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    302\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m continue_training:\n\u001b[0;32m    303\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\my tools\\environments\\pytorch_2_1_0_cuda_11_8\\Lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:195\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.collect_rollouts\u001b[1;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    191\u001b[0m         \u001b[38;5;66;03m# Otherwise, clip the actions to avoid out of bound error\u001b[39;00m\n\u001b[0;32m    192\u001b[0m         \u001b[38;5;66;03m# as we are sampling from an unbounded Gaussian distribution\u001b[39;00m\n\u001b[0;32m    193\u001b[0m         clipped_actions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(actions, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mlow, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mhigh)\n\u001b[1;32m--> 195\u001b[0m new_obs, rewards, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclipped_actions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mnum_envs\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# Give access to local variables\u001b[39;00m\n",
      "File \u001b[1;32mc:\\my tools\\environments\\pytorch_2_1_0_cuda_11_8\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py:206\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[1;34m(self, actions)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;124;03mStep the environments with the given action\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \n\u001b[0;32m    202\u001b[0m \u001b[38;5;124;03m:param actions: the action\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;124;03m:return: observation, reward, done, information\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_async(actions)\n\u001b[1;32m--> 206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\my tools\\environments\\pytorch_2_1_0_cuda_11_8\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py:58\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m VecEnvStepReturn:\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;66;03m# Avoid circular imports\u001b[39;00m\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m env_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_envs):\n\u001b[1;32m---> 58\u001b[0m         obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_rews[env_idx], terminated, truncated, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_infos[env_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menvs\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactions\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m         \u001b[38;5;66;03m# convert to SB3 VecEnv api\u001b[39;00m\n\u001b[0;32m     62\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones[env_idx] \u001b[38;5;241m=\u001b[39m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated\n",
      "File \u001b[1;32mc:\\my tools\\environments\\pytorch_2_1_0_cuda_11_8\\Lib\\site-packages\\stable_baselines3\\common\\monitor.py:94\u001b[0m, in \u001b[0;36mMonitor.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneeds_reset:\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTried to step environment that needs reset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 94\u001b[0m observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrewards\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mfloat\u001b[39m(reward))\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated:\n",
      "Cell \u001b[1;32mIn[8], line 25\u001b[0m, in \u001b[0;36mFrameStackingWrapper.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[1;32m---> 25\u001b[0m     obs, reward, done, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframes[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframes[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# Shift frames\u001b[39;00m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframes[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m obs  \u001b[38;5;66;03m# Add new frame\u001b[39;00m\n",
      "File \u001b[1;32mc:\\my tools\\environments\\pytorch_2_1_0_cuda_11_8\\Lib\\site-packages\\gymnasium\\wrappers\\order_enforcing.py:56\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling env.reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\my tools\\environments\\pytorch_2_1_0_cuda_11_8\\Lib\\site-packages\\gymnasium\\wrappers\\env_checker.py:51\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_step_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, action)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\glucas\\Desktop\\New folder\\super_mario_world-agent\\src\\gamenv\\gameenv.py:100\u001b[0m, in \u001b[0;36mGameEnv.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     97\u001b[0m game_over \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m GetForegroundWindow() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcamera\u001b[38;5;241m.\u001b[39mwindow_handle:\n\u001b[1;32m--> 100\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mGetWindowText(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcamera\u001b[38;5;241m.\u001b[39mwindow_handle)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m cannot be minimized.\u001b[39m\u001b[38;5;124m\"\u001b[39m) \n\u001b[0;32m    102\u001b[0m \u001b[38;5;66;03m#self.toggle_pause()\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;66;03m#print(\"unpaused\")\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;66;03m# self.release_key('right_arrow')\u001b[39;00m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;66;03m# self.release_key('c')\u001b[39;00m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelease_key(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mException\u001b[0m: mario - Snes9x 1.62.3 cannot be minimized."
     ]
    }
   ],
   "source": [
    "# Train the model with the custom callback\n",
    "model.learn(total_timesteps=50000, callback=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa497d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ActorCriticPolicy(\n",
       "  (features_extractor): CustomCNN(\n",
       "    (cnn): Sequential(\n",
       "      (0): Conv2d(3, 32, kernel_size=(8, 8), stride=(4, 4))\n",
       "      (1): ReLU()\n",
       "      (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
       "      (3): ReLU()\n",
       "      (4): Flatten(start_dim=1, end_dim=-1)\n",
       "    )\n",
       "    (lstm): LSTM(4096, 256, batch_first=True)\n",
       "    (linear): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (pi_features_extractor): CustomCNN(\n",
       "    (cnn): Sequential(\n",
       "      (0): Conv2d(3, 32, kernel_size=(8, 8), stride=(4, 4))\n",
       "      (1): ReLU()\n",
       "      (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
       "      (3): ReLU()\n",
       "      (4): Flatten(start_dim=1, end_dim=-1)\n",
       "    )\n",
       "    (lstm): LSTM(4096, 256, batch_first=True)\n",
       "    (linear): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (vf_features_extractor): CustomCNN(\n",
       "    (cnn): Sequential(\n",
       "      (0): Conv2d(3, 32, kernel_size=(8, 8), stride=(4, 4))\n",
       "      (1): ReLU()\n",
       "      (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
       "      (3): ReLU()\n",
       "      (4): Flatten(start_dim=1, end_dim=-1)\n",
       "    )\n",
       "    (lstm): LSTM(4096, 256, batch_first=True)\n",
       "    (linear): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (mlp_extractor): MlpExtractor(\n",
       "    (policy_net): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=64, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (3): Tanh()\n",
       "    )\n",
       "    (value_net): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=64, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (3): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (action_net): Linear(in_features=64, out_features=6, bias=True)\n",
       "  (value_net): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9456e5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./ppo_super_mario_tensorboard/PPO_60\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 151      |\n",
      "|    ep_rew_mean     | -5       |\n",
      "| time/              |          |\n",
      "|    fps             | 31       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 33       |\n",
      "|    total_timesteps | 1048     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m env \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mget_env()\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Train the agent\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Save the agent\u001b[39;00m\n\u001b[0;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\my tools\\environments\\pytorch_2_1_0_cuda_11_8\\Lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:315\u001b[0m, in \u001b[0;36mPPO.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    307\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfPPO,\n\u001b[0;32m    308\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    313\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    314\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfPPO:\n\u001b[1;32m--> 315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\my tools\\environments\\pytorch_2_1_0_cuda_11_8\\Lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:313\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    310\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mep_info_buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    311\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dump_logs(iteration)\n\u001b[1;32m--> 313\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    315\u001b[0m callback\u001b[38;5;241m.\u001b[39mon_training_end()\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\my tools\\environments\\pytorch_2_1_0_cuda_11_8\\Lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:207\u001b[0m, in \u001b[0;36mPPO.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    205\u001b[0m approx_kl_divs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    206\u001b[0m \u001b[38;5;66;03m# Do a complete pass on the rollout buffer\u001b[39;00m\n\u001b[1;32m--> 207\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrollout_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollout_buffer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43mactions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrollout_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactions\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction_space\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspaces\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDiscrete\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Convert discrete action from float to long\u001b[39;49;00m\n",
      "File \u001b[1;32mc:\\my tools\\environments\\pytorch_2_1_0_cuda_11_8\\Lib\\site-packages\\stable_baselines3\\common\\buffers.py:504\u001b[0m, in \u001b[0;36mRolloutBuffer.get\u001b[1;34m(self, batch_size)\u001b[0m\n\u001b[0;32m    502\u001b[0m start_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    503\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m start_idx \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_envs:\n\u001b[1;32m--> 504\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstart_idx\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_idx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m     start_idx \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch_size\n",
      "File \u001b[1;32mc:\\my tools\\environments\\pytorch_2_1_0_cuda_11_8\\Lib\\site-packages\\stable_baselines3\\common\\buffers.py:520\u001b[0m, in \u001b[0;36mRolloutBuffer._get_samples\u001b[1;34m(self, batch_inds, env)\u001b[0m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_samples\u001b[39m(\n\u001b[0;32m    508\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    509\u001b[0m     batch_inds: np\u001b[38;5;241m.\u001b[39mndarray,\n\u001b[0;32m    510\u001b[0m     env: Optional[VecNormalize] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    511\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m RolloutBufferSamples:\n\u001b[0;32m    512\u001b[0m     data \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    513\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservations[batch_inds],\n\u001b[0;32m    514\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactions[batch_inds],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    518\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturns[batch_inds]\u001b[38;5;241m.\u001b[39mflatten(),\n\u001b[0;32m    519\u001b[0m     )\n\u001b[1;32m--> 520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m RolloutBufferSamples(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_torch, data)))\n",
      "File \u001b[1;32mc:\\my tools\\environments\\pytorch_2_1_0_cuda_11_8\\Lib\\site-packages\\stable_baselines3\\common\\buffers.py:138\u001b[0m, in \u001b[0;36mBaseBuffer.to_torch\u001b[1;34m(self, array, copy)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;124;03mConvert a numpy array to a PyTorch tensor.\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;124;03mNote: it copies the data by default\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;124;03m:return:\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[1;32m--> 138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m th\u001b[38;5;241m.\u001b[39mas_tensor(array, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Retrieve the environment\n",
    "# env = model.get_env()\n",
    "# Train the agent\n",
    "# model.learn(total_timesteps=100000)\n",
    "# Save the agent\n",
    "\n",
    "model.save(\"model\")\n",
    "# the policy_kwargs are automatically loaded"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
